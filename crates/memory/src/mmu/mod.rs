//! Paging / MMU helpers.

pub mod long;
pub mod mode32;
pub mod pae;

use crate::bus::MemoryBus;

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum AccessType {
    Read,
    Write,
    Execute,
}

impl AccessType {
    pub(crate) fn is_write(self) -> bool {
        matches!(self, Self::Write)
    }

    pub(crate) fn is_execute(self) -> bool {
        matches!(self, Self::Execute)
    }
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum TranslateError {
    /// x86-64 #GP generated by non-canonical virtual addresses in 4-level paging.
    GeneralProtection { vaddr: u64 },
    /// x86 #PF with the encoded page-fault error code bits.
    PageFault { vaddr: u64, code: u32 },
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum PageSize {
    Size4K,
    Size2M,
    Size1G,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct TranslateResult {
    pub paddr: u64,
    pub page_size: PageSize,
}

pub(crate) const PFEC_P: u32 = 1 << 0;
pub(crate) const PFEC_WR: u32 = 1 << 1;
pub(crate) const PFEC_US: u32 = 1 << 2;
pub(crate) const PFEC_RSVD: u32 = 1 << 3;
pub(crate) const PFEC_ID: u32 = 1 << 4;

pub const CR0_PG: u64 = 1 << 31;
pub const CR0_WP: u64 = 1 << 16;
pub const CR4_PSE: u64 = 1 << 4;
pub const CR4_PAE: u64 = 1 << 5;

pub const EFER_LME: u64 = 1 << 8;
pub const EFER_LMA: u64 = 1 << 10;
pub const EFER_NXE: u64 = 1 << 11;

/// Minimal MMU register bundle used for address translation.
#[derive(Debug, Clone, Copy)]
pub struct Mmu {
    pub cr0: u64,
    pub cr3: u64,
    pub cr4: u64,
    pub efer: u64,
    pub cpl: u8,
}

impl Default for Mmu {
    fn default() -> Self {
        Self {
            cr0: 0,
            cr3: 0,
            cr4: 0,
            efer: 0,
            cpl: 0,
        }
    }
}

impl Mmu {
    pub fn translate(
        &self,
        bus: &mut impl MemoryBus,
        linear: u64,
        access: AccessType,
    ) -> Result<u64, TranslateError> {
        translate(
            bus,
            linear,
            access,
            self.cpl,
            self.cr0,
            self.cr3,
            self.cr4,
            self.efer,
        )
    }
}

/// Translate a linear address to a physical address.
///
/// Supported translation modes:
/// - Paging disabled (`CR0.PG=0`): identity mapping (address masked to 32 bits)
/// - 32-bit non-PAE paging (`CR0.PG=1`, `CR4.PAE=0`)
/// - IA-32 PAE paging (3-level) (`CR0.PG=1`, `CR4.PAE=1`, `EFER.LME=0`)
/// - 4-level IA-32e paging (long mode) (`CR0.PG=1`, `CR4.PAE=1`, `EFER.LME=1`)
pub fn translate(
    bus: &mut impl MemoryBus,
    linear: u64,
    access: AccessType,
    cpl: u8,
    cr0: u64,
    cr3: u64,
    cr4: u64,
    efer: u64,
) -> Result<u64, TranslateError> {
    if (cr0 & CR0_PG) == 0 {
        return Ok(linear & 0xFFFF_FFFF);
    }

    if (cr4 & CR4_PAE) == 0 {
        return mode32::translate(bus, linear, access, cpl, cr0, cr3, cr4);
    }

    if (efer & EFER_LME) == 0 {
        return pae::translate(bus, linear, access, cpl, cr0, cr3, efer);
    }

    // IA-32e: the CPU should have set LMA when paging was enabled with LME=1.
    // We dispatch based on LME because some callers may not model LMA yet.
    let _ = efer & EFER_LMA;
    long::translate_4level(bus, linear, access, cr3, cr0, efer, cpl).map(|r| r.paddr)
}
