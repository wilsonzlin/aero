name: Benchmarks

on:
  workflow_dispatch:
  schedule:
    # Nightly run for a stable signal on `main`.
    - cron: "0 3 * * *"
  pull_request:
    # Only run benchmarks when performance-sensitive code changes.
      paths:
        - "Cargo.toml"
        - "Cargo.lock"
        - "crates/aero-cpu-core/**"
        - "crates/aero-x86/**"
        - "crates/aero-cpu-decoder/**"
        - "scripts/bench_compare.py"
        - ".github/workflows/bench.yml"

concurrency:
  group: bench-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  actions: read

jobs:
  bench:
    runs-on: ubuntu-22.04
    timeout-minutes: 30

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Rust
        id: setup-rust
        uses: ./.github/actions/setup-rust
        with:
          toolchain: stable
          locked: always

      - name: Select benchmark profile
        run: |
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            echo "AERO_BENCH_PROFILE=ci" >> "$GITHUB_ENV"
          else
            echo "AERO_BENCH_PROFILE=full" >> "$GITHUB_ENV"
          fi

      - name: Download baseline artifact (previous main run)
        if: github.event_name != 'pull_request'
        continue-on-error: true
        uses: dawidd6/action-download-artifact@v2
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          workflow: bench.yml
          branch: main
          workflow_conclusion: success
          name: criterion
          path: baseline
          if_no_artifact_found: warn

      - name: "Run benchmarks (PR: base commit)"
        if: github.event_name == 'pull_request'
        env:
          BASE_SHA: ${{ github.event.pull_request.base.sha }}
        run: |
          set -euo pipefail
          echo "Benchmarking baseline (base SHA): $BASE_SHA"
          git checkout "$BASE_SHA"

          # Warm up the runner CPU so base/head runs are less sensitive to
          # frequency scaling and low-power states.
          python3 - <<'PY'
          import time
          x = 0
          end = time.time() + 1.0
          while time.time() < end:
              x = (x * 1664525 + 1013904223) & 0xFFFFFFFF
          print(x)
          PY

            if command -v taskset >/dev/null 2>&1; then
              taskset -c 0 cargo bench ${{ steps.setup-rust.outputs.cargo_locked_flag }} -p aero-cpu-core --bench emulator_critical --features legacy-interp -- --noplot
              taskset -c 0 cargo bench ${{ steps.setup-rust.outputs.cargo_locked_flag }} -p aero-cpu-core --bench jit_bookkeeping --features legacy-interp -- --noplot
            else
              cargo bench ${{ steps.setup-rust.outputs.cargo_locked_flag }} -p aero-cpu-core --bench emulator_critical --features legacy-interp -- --noplot
              cargo bench ${{ steps.setup-rust.outputs.cargo_locked_flag }} -p aero-cpu-core --bench jit_bookkeeping --features legacy-interp -- --noplot
            fi

          # Criterion writes benchmark results to `target/criterion`. Move the results
          # out so the next run doesn't overwrite them.
          mkdir -p target/bench-base
          rm -rf target/bench-base/criterion
          mv target/criterion target/bench-base/criterion

          # Avoid thermal bias carrying into the head run.
          sleep 2

      - name: "Run benchmarks (PR: head commit)"
        if: github.event_name == 'pull_request'
        env:
          HEAD_SHA: ${{ github.event.pull_request.head.sha }}
        run: |
          set -euo pipefail
          echo "Benchmarking PR head (head SHA): $HEAD_SHA"
          git checkout "$HEAD_SHA"

          python3 - <<'PY'
          import time
          x = 0
          end = time.time() + 1.0
          while time.time() < end:
              x = (x * 1664525 + 1013904223) & 0xFFFFFFFF
          print(x)
          PY

            if command -v taskset >/dev/null 2>&1; then
              taskset -c 0 cargo bench ${{ steps.setup-rust.outputs.cargo_locked_flag }} -p aero-cpu-core --bench emulator_critical --features legacy-interp -- --noplot
              taskset -c 0 cargo bench ${{ steps.setup-rust.outputs.cargo_locked_flag }} -p aero-cpu-core --bench jit_bookkeeping --features legacy-interp -- --noplot
            else
              cargo bench ${{ steps.setup-rust.outputs.cargo_locked_flag }} -p aero-cpu-core --bench emulator_critical --features legacy-interp -- --noplot
              cargo bench ${{ steps.setup-rust.outputs.cargo_locked_flag }} -p aero-cpu-core --bench jit_bookkeeping --features legacy-interp -- --noplot
            fi

          rm -rf target/bench-new/criterion
          mkdir -p target/bench-new
          mv target/criterion target/bench-new/criterion

      - name: "Compare (PR: base vs head)"
        if: github.event_name == 'pull_request'
        run: |
          set -euo pipefail
          python3 scripts/bench_compare.py \
            --base target/bench-base/criterion \
            --new target/bench-new/criterion \
            --thresholds-file bench/perf_thresholds.json \
            --profile pr-smoke \
            --markdown-out bench_reports/compare.md \
            --json-out bench_reports/compare.json

      - name: Run benchmarks (main/scheduled)
        if: github.event_name != 'pull_request'
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import time
          x = 0
          end = time.time() + 1.0
          while time.time() < end:
              x = (x * 1664525 + 1013904223) & 0xFFFFFFFF
          print(x)
          PY

            if command -v taskset >/dev/null 2>&1; then
              taskset -c 0 cargo bench ${{ steps.setup-rust.outputs.cargo_locked_flag }} -p aero-cpu-core --bench emulator_critical --features legacy-interp -- --noplot
              taskset -c 0 cargo bench ${{ steps.setup-rust.outputs.cargo_locked_flag }} -p aero-cpu-core --bench jit_bookkeeping --features legacy-interp -- --noplot
            else
              cargo bench ${{ steps.setup-rust.outputs.cargo_locked_flag }} -p aero-cpu-core --bench emulator_critical --features legacy-interp -- --noplot
              cargo bench ${{ steps.setup-rust.outputs.cargo_locked_flag }} -p aero-cpu-core --bench jit_bookkeeping --features legacy-interp -- --noplot
            fi

          rm -rf target/bench-new/criterion
          mkdir -p target/bench-new
          mv target/criterion target/bench-new/criterion

      - name: "Compare (main: previous artifact vs current)"
        if: github.event_name != 'pull_request'
        run: |
          set -euo pipefail
          if [ -d baseline/target/bench-new/criterion ]; then
            python3 scripts/bench_compare.py \
              --base baseline/target/bench-new/criterion \
              --new target/bench-new/criterion \
              --thresholds-file bench/perf_thresholds.json \
              --profile nightly \
              --markdown-out bench_reports/compare.md \
              --json-out bench_reports/compare.json
          else
            echo "No baseline artifact found; skipping regression check." >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Upload artifacts (PR)
        if: always() && github.event_name == 'pull_request'
        uses: actions/upload-artifact@v6
        with:
          name: bench-pr
          path: |
            target/bench-base/criterion
            target/bench-new/criterion
            bench_reports/*

      - name: Upload artifacts (main)
        if: always() && github.event_name != 'pull_request'
        uses: actions/upload-artifact@v6
        with:
          name: criterion-run-${{ github.run_id }}
          path: |
            target/bench-new/criterion
            bench_reports/*

      - name: Upload baseline artifact (main)
        if: success() && github.event_name != 'pull_request'
        uses: actions/upload-artifact@v6
        with:
          name: criterion
          path: |
            target/bench-new/criterion
            bench_reports/*
